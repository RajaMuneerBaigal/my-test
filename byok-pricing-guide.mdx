---
title: Bring Your Own Key (BYOK) and Pricing
---

Chatsistant operates on a "pay as you go" basis. Rather than having Message Credits (MCs) baked into existing subscriptions, you
buy them separately via add-ons or connect your own AI API keys to enjoy unlimited usage.

If you use your own AI API keys, then after you exhaust all MCs inside your Chatsistant account, additional AI usage will be charged
against your own API keys.

## Setting up BYOK

To set up your own API key, you will first need to register on the AI provider's website. Chatsistant currently
supports large language models (LLMs) from OpenAI, Anthropic, and Google. In the future, we plan to expand our list of supported
models, potentially incorporating open-source and fine-tuned ones.

### Provider-specific instructions

* OpenAI (GPT models)- [https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys)

* Anthropic (Claude models) - [https://console.anthropic.com/settings/keys](https://console.anthropic.com/settings/keys)

* Google (Gemini models) - [https://ai.google.dev/gemini-api/docs/api-key](https://ai.google.dev/gemini-api/docs/api-key)

After you obtain your API key, store it in a **private and secure** location. Chatsistant recommends that you use a separate API
key for each of your BYOK applications (including Chatsistant), and to never share your API key with anyone else.

Next, log in to Chatsistant and go to the top right corner of the UI. Click the "Profile" icon the bring up a dropdown menu.

<Frame>
  <img src="/images/byok-pricing-guide-1.png" />
</Frame>

Then, click "Account". In the **"AI API Key"** section, pick your AI provider and paste your API key. Then click "Add".
Please note that this is **not** the "Chatsistant API keys" section which is used to generate Chatsistant API keys.

<Frame>
  <img src="/images/byok-pricing-guide-3.png" />
</Frame>

You should be all set.

<Note>
  If this is the first time you create an API key with a provider, there is a
  good chance that your key may be rate and feature limited. For example, as of
  November 1, 2024, all new API keys registered with new OpenAI accounts are
  prohibited from running GPT-4o model series. To lift this restriction, you may
  need to add $5 credt and provide verified billing information within your
  OpenAI account. Different providers may have different policies regarding
  account verification.
</Note>

## Budgeting for AI usage

In general, using your own API key will be more cost efficient than purchasing MC add-ons directly. To help you estimate costs
associated with running your BYOK account, we provide the following references.

<Note>
  LLM providers change their pricing from time to time, so the information we
  provide may not always be up-to-date. For latest information on pricing,
  please visit: 
  
  - OpenAI (GPT models): https://openai.com/pricing 
  - Anthropic (Claude models): https://www.anthropic.com/pricing#anthropic-api
  - Google (Gemini models): https://ai.google.dev/pricing#1\_5flash
</Note>

The simplest estimate you can use is this:

* Each Message Credit costs \~$0.0032 USD

For example, GPT-4-1106-4k uses 20 MCs per query. To estimate the cost in USD, multiply $0.0032 \* 20 = $0.064 USD.

This is a very rough estimate. Actual spend may be around +/- 20% of the estimated number. This is because LLM usage is measured
based on "tokens", and input vs. output tokens cost different amounts even for the same LLM. To understand tokens, we
refer you to this article: [https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them.](https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them.)

There are many parts to a LLM query. At a high level, they can be broken down into:

Input:

* System prompt and metadata

* User-defined base prompt

* Variables and definitions

* Conversation label definitions

* Function metadata and descriptions

* Function parameters

* Function response

* Static RAG context

* Conversation memory

Output:

* Text response

* Response metadata

### OpenAI pricing breakdown

Chatsistant supports a variety of OpenAI LLMs, as well as different versions of the same LLM with custom token limit cutoffs.
To help you budget for your usage, we provide a summary based on our **default** split of reserved input vs. output tokens. Please refer
to the following table (all $ are in USD). Please note that this generally represents an upper limit since not all input / output tokens
in the reservation window are used every single LLM query.

| Model           | Reserved for Input | Reserved for Output | Cost / Input Token | Cost / Output Token | Total Cost per Query |
| --------------- | ------------------ | ------------------- | ------------------ | ------------------- | -------------------- |
| GPT-3.5         | 2800               | 1200                | 0.0000005          | 0.0000015           | 0.0032               |
| GPT-3.5-16k     | 13600              | 2400                | 0.0000005          | 0.0000015           | 0.0104               |
| GPT-4o-mini-1k  | 800                | 200                 | 0.00000015         | 0.0000006           | 0.00024              |
| GPT-4o-mini-2k  | 1600               | 400                 | 0.00000015         | 0.0000006           | 0.00048              |
| GPT-4o-mini-4k  | 2800               | 1200                | 0.00000015         | 0.0000006           | 0.00114              |
| GPT-4o-mini-8k  | 5600               | 2400                | 0.00000015         | 0.0000006           | 0.00228              |
| GPT-4o-mini-16k | 12800              | 3200                | 0.00000015         | 0.0000006           | 0.00384              |
| GPT-4o-mini-32k | 28000              | 4000                | 0.00000015         | 0.0000006           | 0.0066               |
| GPT-4o-mini-64k | 60000              | 4000                | 0.00000015         | 0.0000006           | 0.0114               |
| GPT-4o-1k       | 800                | 200                 | 0.0000025          | 0.00001             | 0.004                |
| GPT-4o-2k       | 1600               | 400                 | 0.0000025          | 0.00001             | 0.008                |
| GPT-4o-4k       | 2800               | 1200                | 0.0000025          | 0.00001             | 0.019                |
| GPT-4o-8k       | 5600               | 2400                | 0.0000025          | 0.00001             | 0.038                |
| GPT-4o-16k      | 12800              | 3200                | 0.0000025          | 0.00001             | 0.064                |
| GPT-4o-32k      | 28000              | 4000                | 0.0000025          | 0.00001             | 0.11                 |
| GPT-4o-64k      | 60000              | 4000                | 0.0000025          | 0.00001             | 0.19                 |
| GPT-4-1106-1k   | 800                | 200                 | 0.00001            | 0.00003             | 0.014                |
| GPT-4-1106-2k   | 1600               | 400                 | 0.00001            | 0.00003             | 0.028                |
| GPT-4-1106-4k   | 2800               | 1200                | 0.00001            | 0.00003             | 0.064                |
| GPT-4-0125-8k   | 5600               | 2400                | 0.00001            | 0.00003             | 0.128                |
| GPT-4-1106-16k  | 12800              | 3200                | 0.00001            | 0.00003             | 0.224                |
| GPT-4-1106-32k  | 28000              | 4000                | 0.00001            | 0.00003             | 0.4                  |
| GPT-4-1106-64k  | 60000              | 4000                | 0.00001            | 0.00003             | 0.72                 |

